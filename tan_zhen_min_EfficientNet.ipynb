{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, re\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sns.set_theme(style = \"dark\", \n",
    "        color_codes = True,\n",
    "        font_scale = 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_partition_folder(partition=\"train\"):\n",
    "    partition_folder = os.path.join(os.getcwd(),'image_csv',partition)\n",
    "    \n",
    "\n",
    "    image_indexes,images,labels = [],[],[]\n",
    "\n",
    "    for image_fname in os.listdir(partition_folder):\n",
    "        image_re = re.match(r'([0-9]+)_([0-9]+)\\.csv',image_fname)\n",
    "        image_indexes.append(image_re.group(1))\n",
    "        labels.append(image_re.group(2))\n",
    "        images.append(np.loadtxt(os.path.join(partition_folder,image_fname),delimiter=',',dtype=np.float32))\n",
    "\n",
    "    image_df = pd.DataFrame({'img_index':image_indexes,'image':images,'label':labels})\n",
    "\n",
    "    image_df[\"img_index\"] = image_df[\"img_index\"].astype(int)\n",
    "    image_df[\"label\"] = image_df[\"label\"].astype(int)\n",
    "\n",
    "    return image_df.sort_values(by=\"img_index\").reset_index(drop=True).drop(['img_index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 4.0, 4.0, 4.0,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  label\n",
       "0  [[3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 4.0, 4.0, 4.0,...      3\n",
       "1  [[2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0,...      0\n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      2\n",
       "3  [[1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0,...      1\n",
       "4  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = load_partition_folder()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10618 entries, 0 to 10617\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   image   10618 non-null  object\n",
      " 1   label   10618 non-null  int32 \n",
      "dtypes: int32(1), object(1)\n",
      "memory usage: 124.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  label\n",
       "0  [[2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...      0\n",
       "1  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...      0\n",
       "2  [[1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0,...      0\n",
       "3  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...      0\n",
       "4  [[1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0,...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = load_partition_folder(partition='test')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1405 entries, 0 to 1404\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   image   1405 non-null   object\n",
      " 1   label   1405 non-null   int32 \n",
      "dtypes: int32(1), object(1)\n",
      "memory usage: 16.6+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = train_df['image']\n",
    "y_train = train_df['label']\n",
    "\n",
    "X_test = test_df['image']\n",
    "y_test = test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "332/332 [==============================] - 619s 2s/step - loss: 0.5785 - accuracy: 0.7629 - val_loss: 0.3615 - val_accuracy: 0.8683\n",
      "Epoch 2/5\n",
      "332/332 [==============================] - 622s 2s/step - loss: 0.3964 - accuracy: 0.8453 - val_loss: 0.3395 - val_accuracy: 0.8747\n",
      "Epoch 3/5\n",
      "332/332 [==============================] - 646s 2s/step - loss: 0.3410 - accuracy: 0.8697 - val_loss: 0.2592 - val_accuracy: 0.9011\n",
      "Epoch 4/5\n",
      "332/332 [==============================] - 642s 2s/step - loss: 0.2900 - accuracy: 0.8927 - val_loss: 0.2753 - val_accuracy: 0.8940\n",
      "Epoch 5/5\n",
      "332/332 [==============================] - 763s 2s/step - loss: 0.2622 - accuracy: 0.8980 - val_loss: 0.2372 - val_accuracy: 0.9210\n",
      "Epoch 1/5\n",
      "332/332 [==============================] - 866s 3s/step - loss: 0.3617 - accuracy: 0.8625 - val_loss: 0.1871 - val_accuracy: 0.9267\n",
      "Epoch 2/5\n",
      "332/332 [==============================] - 879s 3s/step - loss: 0.2076 - accuracy: 0.9217 - val_loss: 0.1443 - val_accuracy: 0.9445\n",
      "Epoch 3/5\n",
      "332/332 [==============================] - 801s 2s/step - loss: 0.1526 - accuracy: 0.9466 - val_loss: 0.1240 - val_accuracy: 0.9559\n",
      "Epoch 4/5\n",
      "332/332 [==============================] - 769s 2s/step - loss: 0.1225 - accuracy: 0.9546 - val_loss: 0.1053 - val_accuracy: 0.9673\n",
      "Epoch 5/5\n",
      "332/332 [==============================] - 769s 2s/step - loss: 0.1013 - accuracy: 0.9618 - val_loss: 0.1177 - val_accuracy: 0.9637\n",
      "44/44 [==============================] - 71s 2s/step - loss: 0.1177 - accuracy: 0.9637\n",
      "Test accuracy: 96.37%\n"
     ]
    }
   ],
   "source": [
    "# Attempt (Base Model) - With Freeze and Unfreeze layer \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parameters\n",
    "img_size = (240, 240)\n",
    "channels = 3\n",
    "img_shape = (img_size[0], img_size[1], channels)\n",
    "num_classes = 4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example: Convert DataFrame to numpy array\n",
    "X_train = np.array(train_df['image'].tolist())\n",
    "y_train = train_df['label'].values\n",
    "X_test = np.array(test_df['image'].tolist())\n",
    "y_test = test_df['label'].values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Ensure images have 3 channels\n",
    "X_train = np.array([cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) if img.shape[-1] != 3 else img for img in X_train])\n",
    "X_test = np.array([cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) if img.shape[-1] != 3 else img for img in X_test])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train_encoded = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_encoded = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load pre-trained EfficientNetB0 with a different input size\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=img_shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Add custom classification layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)  # Output layer for 4 classes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Compile the model for multi-class classification\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Add EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train_encoded, epochs=5, validation_data=(X_test, y_test_encoded), callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Unfreeze some layers and fine-tune\n",
    "for layer in base_model.layers[-20:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Recompile the model with a lower learning rate\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Continue training\n",
    "history_fine = model.fit(X_train, y_train_encoded, epochs=5, validation_data=(X_test, y_test_encoded))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded)\n",
    "print(f'Test accuracy: {test_accuracy * 100:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For Base Model Attempt\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "acc2 = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss2 = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    " \n",
    "epochs = range(1,len(acc2)+1)\n",
    " \n",
    "# Creating subplots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(7,3))\n",
    " \n",
    "axes[0].plot(epochs, acc2,'b',label='Train Accuracy')\n",
    "axes[0].plot(epochs, val_acc,'r',label='Test Accuracy')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    " \n",
    "axes[1].plot(epochs, loss2,'b',label='Train Loss')\n",
    "axes[1].plot(epochs, val_loss,'r',label='Test Loss')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    " \n",
    "# Adjusting layout for better spacing\n",
    "plt.tight_layout()\n",
    " \n",
    "# Display the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 27 Complete [00h 54m 25s]\n",
      "val_accuracy: 0.8797153234481812\n",
      "\n",
      "Best val_accuracy So Far: 0.9473309516906738\n",
      "Total elapsed time: 15d 19h 45m 55s\n",
      "Epoch 1/5\n",
      "332/332 [==============================] - 673s 2s/step - loss: 0.5724 - accuracy: 0.7723 - val_loss: 0.4038 - val_accuracy: 0.8399\n",
      "Epoch 2/5\n",
      "332/332 [==============================] - 693s 2s/step - loss: 0.4223 - accuracy: 0.8371 - val_loss: 0.3672 - val_accuracy: 0.8612\n",
      "Epoch 3/5\n",
      "332/332 [==============================] - 645s 2s/step - loss: 0.3652 - accuracy: 0.8592 - val_loss: 0.2714 - val_accuracy: 0.9025\n",
      "Epoch 4/5\n",
      "332/332 [==============================] - 666s 2s/step - loss: 0.3357 - accuracy: 0.8752 - val_loss: 0.2336 - val_accuracy: 0.9132\n",
      "Epoch 5/5\n",
      "332/332 [==============================] - 667s 2s/step - loss: 0.3035 - accuracy: 0.8857 - val_loss: 0.2330 - val_accuracy: 0.9153\n",
      "44/44 [==============================] - 73s 2s/step - loss: 0.2330 - accuracy: 0.9153\n",
      "Test accuracy: 91.53%\n"
     ]
    }
   ],
   "source": [
    "# Attempt with Random Search (Benchmark to beat: 96.53%) Now: 91.53%\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import cv2\n",
    "import keras_tuner as kt\n",
    "\n",
    "# Parameters\n",
    "img_size = (240, 240)\n",
    "channels = 3\n",
    "img_shape = (img_size[0], img_size[1], channels)\n",
    "num_classes = 4\n",
    "\n",
    "# Example: Convert DataFrame to numpy array\n",
    "X_train = np.array(train_df['image'].tolist())\n",
    "y_train = train_df['label'].values\n",
    "X_test = np.array(test_df['image'].tolist())\n",
    "y_test = test_df['label'].values\n",
    "\n",
    "# Ensure images have 3 channels\n",
    "X_train = np.array([cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) if img.shape[-1] != 3 else img for img in X_train])\n",
    "X_test = np.array([cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) if img.shape[-1] != 3 else img for img in X_test])\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train_encoded = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_encoded = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "# Define model builder function for Keras Tuner\n",
    "def build_model(hp):\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=img_shape)\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Tune the number of units in the dense layer\n",
    "    x = Dense(units=hp.Int('units', min_value=512, max_value=2048, step=256), activation='relu')(x)\n",
    "    \n",
    "    # Tune the dropout rate\n",
    "    x = Dropout(rate=hp.Float('dropout', min_value=0.2, max_value=0.5, step=0.1))(x)\n",
    "    \n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # Tune the learning rate for the optimizer\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Instantiate the tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,  # Specify the number of trials\n",
    "    executions_per_trial=1,  # Specify how many models to build and fit for each trial\n",
    "    directory='my_dir',\n",
    "    project_name='efficientnet_tuning'\n",
    ")\n",
    "\n",
    "# Add EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "tuner.search(X_train, y_train_encoded, epochs=5, validation_data=(X_test, y_test_encoded), callbacks=[early_stopping])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Build the model with the optimal hyperparameters and train it\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Freeze the base model layers again for initial training\n",
    "for layer in model.layers[:-3]:  # Assuming the last 3 layers are the custom layers\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model with the best hyperparameters\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_hps.get('learning_rate')),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(X_train, y_train_encoded, epochs=5, validation_data=(X_test, y_test_encoded), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded)\n",
    "print(f'Test accuracy: {test_accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir\\efficientnet_tuning\\tuner0.json\n",
      "Epoch 1/5\n",
      "332/332 [==============================] - 2400s 7s/step - loss: 0.2823 - accuracy: 0.9034 - val_loss: 1.1844 - val_accuracy: 0.6911\n",
      "Epoch 2/5\n",
      "332/332 [==============================] - 2408s 7s/step - loss: 0.1236 - accuracy: 0.9609 - val_loss: 0.2386 - val_accuracy: 0.9103\n",
      "Epoch 3/5\n",
      "332/332 [==============================] - 2421s 7s/step - loss: 0.0848 - accuracy: 0.9724 - val_loss: 2.2346 - val_accuracy: 0.3829\n",
      "Epoch 4/5\n",
      "332/332 [==============================] - 2742s 8s/step - loss: 0.0672 - accuracy: 0.9782 - val_loss: 0.5246 - val_accuracy: 0.7922\n",
      "Epoch 5/5\n",
      "332/332 [==============================] - 2485s 7s/step - loss: 0.0627 - accuracy: 0.9801 - val_loss: 1.5329 - val_accuracy: 0.6192\n",
      "44/44 [==============================] - 67s 2s/step - loss: 0.2386 - accuracy: 0.9103\n",
      "Test accuracy: 91.03%\n"
     ]
    }
   ],
   "source": [
    "# Attempt with Random Search 2 (Benchmark to beat: 96.53%) Now: 91.03% \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import cv2\n",
    "import keras_tuner as kt\n",
    "\n",
    "# Parameters\n",
    "img_size = (240, 240)\n",
    "channels = 3\n",
    "img_shape = (img_size[0], img_size[1], channels)\n",
    "num_classes = 4\n",
    "\n",
    "# Example: Convert DataFrame to numpy array\n",
    "X_train = np.array(train_df['image'].tolist())\n",
    "y_train = train_df['label'].values\n",
    "X_test = np.array(test_df['image'].tolist())\n",
    "y_test = test_df['label'].values\n",
    "\n",
    "# Ensure images have 3 channels\n",
    "X_train = np.array([cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) if img.shape[-1] != 3 else img for img in X_train])\n",
    "X_test = np.array([cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) if img.shape[-1] != 3 else img for img in X_test])\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train_encoded = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_encoded = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "# Define model builder function for Keras Tuner\n",
    "def build_model(hp):\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=img_shape)\n",
    "    \n",
    "    # Tune whether to train the base model layers\n",
    "    freeze_layers = hp.Boolean('freeze_layers')\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = not freeze_layers\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Tune the number of units in the dense layer\n",
    "    x = Dense(units=hp.Int('units', min_value=512, max_value=2048, step=256), activation='relu')(x)\n",
    "    \n",
    "    # Tune the dropout rate\n",
    "    x = Dropout(rate=hp.Float('dropout', min_value=0.2, max_value=0.5, step=0.1))(x)\n",
    "    \n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # Tune the learning rate for the optimizer\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Instantiate the tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,  # Specify the number of trials\n",
    "    executions_per_trial=1,  # Specify how many models to build and fit for each trial\n",
    "    directory='my_dir',\n",
    "    project_name='efficientnet_tuning'\n",
    ")\n",
    "\n",
    "# Add EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "tuner.search(X_train, y_train_encoded, epochs=10, validation_data=(X_test, y_test_encoded), callbacks=[early_stopping])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Build the model with the optimal hyperparameters and train it\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(X_train, y_train_encoded, epochs=5, validation_data=(X_test, y_test_encoded), callbacks=[early_stopping])\n",
    "\n",
    "# Unfreeze some layers for fine-tuning if the model was initially frozen\n",
    "if best_hps.get('freeze_layers'):\n",
    "    for layer in model.layers[-20:]:  # Fine-tuning the last 20 layers\n",
    "        layer.trainable = True\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history_fine = model.fit(X_train, y_train_encoded, epochs=5, validation_data=(X_test, y_test_encoded), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded)\n",
    "print(f'Test accuracy: {test_accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 3\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 512, 'max_value': 2048, 'step': 256, 'sampling': 'linear'}\n",
      "dropout (Float)\n",
      "{'default': 0.2, 'conditions': [], 'min_value': 0.2, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = EarlyStopping(monitor='val_accuracy',patience=3)\n",
    "tuner.search(X_train, y_train, epochs=15,batch_size=32, validation_data=(X_test, y_test), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 71s 2s/step\n",
      "[0 0 0 ... 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "# For Attempt 5 \n",
    "import numpy as np\n",
    "predict_x = model.predict(X_test)\n",
    "predict1 = np.argmax(predict_x, axis = 1)\n",
    "print(predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.99      0.91      0.95       309\n",
      "     Class 1       0.93      0.95      0.94       335\n",
      "     Class 2       0.99      0.99      0.99       399\n",
      "     Class 3       0.95      0.99      0.97       362\n",
      "\n",
      "    accuracy                           0.96      1405\n",
      "   macro avg       0.96      0.96      0.96      1405\n",
      "weighted avg       0.96      0.96      0.96      1405\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For Attempt 5 \n",
    "num_classes = 4\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = [\"Class {}\".format(i) for i in range(num_classes)]\n",
    "print(classification_report(y_test, predict1, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 240, 240, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " rescaling (Rescaling)          (None, 240, 240, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " normalization (Normalization)  (None, 240, 240, 3)  7           ['rescaling[0][0]']              \n",
      "                                                                                                  \n",
      " rescaling_1 (Rescaling)        (None, 240, 240, 3)  0           ['normalization[0][0]']          \n",
      "                                                                                                  \n",
      " stem_conv_pad (ZeroPadding2D)  (None, 241, 241, 3)  0           ['rescaling_1[0][0]']            \n",
      "                                                                                                  \n",
      " stem_conv (Conv2D)             (None, 120, 120, 32  864         ['stem_conv_pad[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " stem_bn (BatchNormalization)   (None, 120, 120, 32  128         ['stem_conv[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " stem_activation (Activation)   (None, 120, 120, 32  0           ['stem_bn[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1a_dwconv (DepthwiseConv2  (None, 120, 120, 32  288        ['stem_activation[0][0]']        \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " block1a_bn (BatchNormalization  (None, 120, 120, 32  128        ['block1a_dwconv[0][0]']         \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block1a_activation (Activation  (None, 120, 120, 32  0          ['block1a_bn[0][0]']             \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block1a_se_squeeze (GlobalAver  (None, 32)          0           ['block1a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block1a_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block1a_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block1a_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block1a_se_excite (Multiply)   (None, 120, 120, 32  0           ['block1a_activation[0][0]',     \n",
      "                                )                                 'block1a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block1a_project_conv (Conv2D)  (None, 120, 120, 16  512         ['block1a_se_excite[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1a_project_bn (BatchNorma  (None, 120, 120, 16  64         ['block1a_project_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " block2a_expand_conv (Conv2D)   (None, 120, 120, 96  1536        ['block1a_project_bn[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block2a_expand_bn (BatchNormal  (None, 120, 120, 96  384        ['block2a_expand_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block2a_expand_activation (Act  (None, 120, 120, 96  0          ['block2a_expand_bn[0][0]']      \n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " block2a_dwconv_pad (ZeroPaddin  (None, 121, 121, 96  0          ['block2a_expand_activation[0][0]\n",
      " g2D)                           )                                ']                               \n",
      "                                                                                                  \n",
      " block2a_dwconv (DepthwiseConv2  (None, 60, 60, 96)  864         ['block2a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block2a_bn (BatchNormalization  (None, 60, 60, 96)  384         ['block2a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2a_activation (Activation  (None, 60, 60, 96)  0           ['block2a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2a_se_squeeze (GlobalAver  (None, 96)          0           ['block2a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block2a_se_reshape (Reshape)   (None, 1, 1, 96)     0           ['block2a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block2a_se_reduce (Conv2D)     (None, 1, 1, 4)      388         ['block2a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block2a_se_expand (Conv2D)     (None, 1, 1, 96)     480         ['block2a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block2a_se_excite (Multiply)   (None, 60, 60, 96)   0           ['block2a_activation[0][0]',     \n",
      "                                                                  'block2a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block2a_project_conv (Conv2D)  (None, 60, 60, 24)   2304        ['block2a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block2a_project_bn (BatchNorma  (None, 60, 60, 24)  96          ['block2a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block2b_expand_conv (Conv2D)   (None, 60, 60, 144)  3456        ['block2a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_expand_bn (BatchNormal  (None, 60, 60, 144)  576        ['block2b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block2b_expand_activation (Act  (None, 60, 60, 144)  0          ['block2b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block2b_dwconv (DepthwiseConv2  (None, 60, 60, 144)  1296       ['block2b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block2b_bn (BatchNormalization  (None, 60, 60, 144)  576        ['block2b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2b_activation (Activation  (None, 60, 60, 144)  0          ['block2b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2b_se_squeeze (GlobalAver  (None, 144)         0           ['block2b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block2b_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block2b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block2b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block2b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block2b_se_excite (Multiply)   (None, 60, 60, 144)  0           ['block2b_activation[0][0]',     \n",
      "                                                                  'block2b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block2b_project_conv (Conv2D)  (None, 60, 60, 24)   3456        ['block2b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block2b_project_bn (BatchNorma  (None, 60, 60, 24)  96          ['block2b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block2b_drop (Dropout)         (None, 60, 60, 24)   0           ['block2b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_add (Add)              (None, 60, 60, 24)   0           ['block2b_drop[0][0]',           \n",
      "                                                                  'block2a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3a_expand_conv (Conv2D)   (None, 60, 60, 144)  3456        ['block2b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block3a_expand_bn (BatchNormal  (None, 60, 60, 144)  576        ['block3a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block3a_expand_activation (Act  (None, 60, 60, 144)  0          ['block3a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block3a_dwconv_pad (ZeroPaddin  (None, 63, 63, 144)  0          ['block3a_expand_activation[0][0]\n",
      " g2D)                                                            ']                               \n",
      "                                                                                                  \n",
      " block3a_dwconv (DepthwiseConv2  (None, 30, 30, 144)  3600       ['block3a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block3a_bn (BatchNormalization  (None, 30, 30, 144)  576        ['block3a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3a_activation (Activation  (None, 30, 30, 144)  0          ['block3a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3a_se_squeeze (GlobalAver  (None, 144)         0           ['block3a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block3a_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block3a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block3a_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block3a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block3a_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block3a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block3a_se_excite (Multiply)   (None, 30, 30, 144)  0           ['block3a_activation[0][0]',     \n",
      "                                                                  'block3a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block3a_project_conv (Conv2D)  (None, 30, 30, 40)   5760        ['block3a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block3a_project_bn (BatchNorma  (None, 30, 30, 40)  160         ['block3a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block3b_expand_conv (Conv2D)   (None, 30, 30, 240)  9600        ['block3a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_expand_bn (BatchNormal  (None, 30, 30, 240)  960        ['block3b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block3b_expand_activation (Act  (None, 30, 30, 240)  0          ['block3b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block3b_dwconv (DepthwiseConv2  (None, 30, 30, 240)  6000       ['block3b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block3b_bn (BatchNormalization  (None, 30, 30, 240)  960        ['block3b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3b_activation (Activation  (None, 30, 30, 240)  0          ['block3b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3b_se_squeeze (GlobalAver  (None, 240)         0           ['block3b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block3b_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block3b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block3b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block3b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block3b_se_excite (Multiply)   (None, 30, 30, 240)  0           ['block3b_activation[0][0]',     \n",
      "                                                                  'block3b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block3b_project_conv (Conv2D)  (None, 30, 30, 40)   9600        ['block3b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block3b_project_bn (BatchNorma  (None, 30, 30, 40)  160         ['block3b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block3b_drop (Dropout)         (None, 30, 30, 40)   0           ['block3b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_add (Add)              (None, 30, 30, 40)   0           ['block3b_drop[0][0]',           \n",
      "                                                                  'block3a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4a_expand_conv (Conv2D)   (None, 30, 30, 240)  9600        ['block3b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4a_expand_bn (BatchNormal  (None, 30, 30, 240)  960        ['block4a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4a_expand_activation (Act  (None, 30, 30, 240)  0          ['block4a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4a_dwconv_pad (ZeroPaddin  (None, 31, 31, 240)  0          ['block4a_expand_activation[0][0]\n",
      " g2D)                                                            ']                               \n",
      "                                                                                                  \n",
      " block4a_dwconv (DepthwiseConv2  (None, 15, 15, 240)  2160       ['block4a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block4a_bn (BatchNormalization  (None, 15, 15, 240)  960        ['block4a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4a_activation (Activation  (None, 15, 15, 240)  0          ['block4a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4a_se_squeeze (GlobalAver  (None, 240)         0           ['block4a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4a_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block4a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4a_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block4a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4a_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block4a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_se_excite (Multiply)   (None, 15, 15, 240)  0           ['block4a_activation[0][0]',     \n",
      "                                                                  'block4a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_project_conv (Conv2D)  (None, 15, 15, 80)   19200       ['block4a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_project_bn (BatchNorma  (None, 15, 15, 80)  320         ['block4a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4b_expand_conv (Conv2D)   (None, 15, 15, 480)  38400       ['block4a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_expand_bn (BatchNormal  (None, 15, 15, 480)  1920       ['block4b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4b_expand_activation (Act  (None, 15, 15, 480)  0          ['block4b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4b_dwconv (DepthwiseConv2  (None, 15, 15, 480)  4320       ['block4b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block4b_bn (BatchNormalization  (None, 15, 15, 480)  1920       ['block4b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4b_activation (Activation  (None, 15, 15, 480)  0          ['block4b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4b_se_squeeze (GlobalAver  (None, 480)         0           ['block4b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4b_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_se_excite (Multiply)   (None, 15, 15, 480)  0           ['block4b_activation[0][0]',     \n",
      "                                                                  'block4b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_project_conv (Conv2D)  (None, 15, 15, 80)   38400       ['block4b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_project_bn (BatchNorma  (None, 15, 15, 80)  320         ['block4b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4b_drop (Dropout)         (None, 15, 15, 80)   0           ['block4b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_add (Add)              (None, 15, 15, 80)   0           ['block4b_drop[0][0]',           \n",
      "                                                                  'block4a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_expand_conv (Conv2D)   (None, 15, 15, 480)  38400       ['block4b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4c_expand_bn (BatchNormal  (None, 15, 15, 480)  1920       ['block4c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4c_expand_activation (Act  (None, 15, 15, 480)  0          ['block4c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4c_dwconv (DepthwiseConv2  (None, 15, 15, 480)  4320       ['block4c_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block4c_bn (BatchNormalization  (None, 15, 15, 480)  1920       ['block4c_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4c_activation (Activation  (None, 15, 15, 480)  0          ['block4c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4c_se_squeeze (GlobalAver  (None, 480)         0           ['block4c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4c_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_se_excite (Multiply)   (None, 15, 15, 480)  0           ['block4c_activation[0][0]',     \n",
      "                                                                  'block4c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_project_conv (Conv2D)  (None, 15, 15, 80)   38400       ['block4c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_project_bn (BatchNorma  (None, 15, 15, 80)  320         ['block4c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4c_drop (Dropout)         (None, 15, 15, 80)   0           ['block4c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_add (Add)              (None, 15, 15, 80)   0           ['block4c_drop[0][0]',           \n",
      "                                                                  'block4b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5a_expand_conv (Conv2D)   (None, 15, 15, 480)  38400       ['block4c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5a_expand_bn (BatchNormal  (None, 15, 15, 480)  1920       ['block5a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block5a_expand_activation (Act  (None, 15, 15, 480)  0          ['block5a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block5a_dwconv (DepthwiseConv2  (None, 15, 15, 480)  12000      ['block5a_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block5a_bn (BatchNormalization  (None, 15, 15, 480)  1920       ['block5a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5a_activation (Activation  (None, 15, 15, 480)  0          ['block5a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5a_se_squeeze (GlobalAver  (None, 480)         0           ['block5a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5a_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block5a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5a_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block5a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5a_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block5a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_se_excite (Multiply)   (None, 15, 15, 480)  0           ['block5a_activation[0][0]',     \n",
      "                                                                  'block5a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_project_conv (Conv2D)  (None, 15, 15, 112)  53760       ['block5a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_project_bn (BatchNorma  (None, 15, 15, 112)  448        ['block5a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5b_expand_conv (Conv2D)   (None, 15, 15, 672)  75264       ['block5a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_expand_bn (BatchNormal  (None, 15, 15, 672)  2688       ['block5b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block5b_expand_activation (Act  (None, 15, 15, 672)  0          ['block5b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block5b_dwconv (DepthwiseConv2  (None, 15, 15, 672)  16800      ['block5b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block5b_bn (BatchNormalization  (None, 15, 15, 672)  2688       ['block5b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5b_activation (Activation  (None, 15, 15, 672)  0          ['block5b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5b_se_squeeze (GlobalAver  (None, 672)         0           ['block5b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5b_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_se_excite (Multiply)   (None, 15, 15, 672)  0           ['block5b_activation[0][0]',     \n",
      "                                                                  'block5b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_project_conv (Conv2D)  (None, 15, 15, 112)  75264       ['block5b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_project_bn (BatchNorma  (None, 15, 15, 112)  448        ['block5b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5b_drop (Dropout)         (None, 15, 15, 112)  0           ['block5b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_add (Add)              (None, 15, 15, 112)  0           ['block5b_drop[0][0]',           \n",
      "                                                                  'block5a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_expand_conv (Conv2D)   (None, 15, 15, 672)  75264       ['block5b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5c_expand_bn (BatchNormal  (None, 15, 15, 672)  2688       ['block5c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block5c_expand_activation (Act  (None, 15, 15, 672)  0          ['block5c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block5c_dwconv (DepthwiseConv2  (None, 15, 15, 672)  16800      ['block5c_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block5c_bn (BatchNormalization  (None, 15, 15, 672)  2688       ['block5c_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5c_activation (Activation  (None, 15, 15, 672)  0          ['block5c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5c_se_squeeze (GlobalAver  (None, 672)         0           ['block5c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5c_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_se_excite (Multiply)   (None, 15, 15, 672)  0           ['block5c_activation[0][0]',     \n",
      "                                                                  'block5c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_project_conv (Conv2D)  (None, 15, 15, 112)  75264       ['block5c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_project_bn (BatchNorma  (None, 15, 15, 112)  448        ['block5c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5c_drop (Dropout)         (None, 15, 15, 112)  0           ['block5c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_add (Add)              (None, 15, 15, 112)  0           ['block5c_drop[0][0]',           \n",
      "                                                                  'block5b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6a_expand_conv (Conv2D)   (None, 15, 15, 672)  75264       ['block5c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6a_expand_bn (BatchNormal  (None, 15, 15, 672)  2688       ['block6a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6a_expand_activation (Act  (None, 15, 15, 672)  0          ['block6a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6a_dwconv_pad (ZeroPaddin  (None, 19, 19, 672)  0          ['block6a_expand_activation[0][0]\n",
      " g2D)                                                            ']                               \n",
      "                                                                                                  \n",
      " block6a_dwconv (DepthwiseConv2  (None, 8, 8, 672)   16800       ['block6a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6a_bn (BatchNormalization  (None, 8, 8, 672)   2688        ['block6a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6a_activation (Activation  (None, 8, 8, 672)   0           ['block6a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6a_se_squeeze (GlobalAver  (None, 672)         0           ['block6a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6a_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block6a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6a_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block6a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6a_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block6a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_se_excite (Multiply)   (None, 8, 8, 672)    0           ['block6a_activation[0][0]',     \n",
      "                                                                  'block6a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_project_conv (Conv2D)  (None, 8, 8, 192)    129024      ['block6a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_project_bn (BatchNorma  (None, 8, 8, 192)   768         ['block6a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6b_expand_conv (Conv2D)   (None, 8, 8, 1152)   221184      ['block6a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_expand_bn (BatchNormal  (None, 8, 8, 1152)  4608        ['block6b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6b_expand_activation (Act  (None, 8, 8, 1152)  0           ['block6b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6b_dwconv (DepthwiseConv2  (None, 8, 8, 1152)  28800       ['block6b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6b_bn (BatchNormalization  (None, 8, 8, 1152)  4608        ['block6b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6b_activation (Activation  (None, 8, 8, 1152)  0           ['block6b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6b_se_squeeze (GlobalAver  (None, 1152)        0           ['block6b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6b_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_se_excite (Multiply)   (None, 8, 8, 1152)   0           ['block6b_activation[0][0]',     \n",
      "                                                                  'block6b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_project_conv (Conv2D)  (None, 8, 8, 192)    221184      ['block6b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_project_bn (BatchNorma  (None, 8, 8, 192)   768         ['block6b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6b_drop (Dropout)         (None, 8, 8, 192)    0           ['block6b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_add (Add)              (None, 8, 8, 192)    0           ['block6b_drop[0][0]',           \n",
      "                                                                  'block6a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_expand_conv (Conv2D)   (None, 8, 8, 1152)   221184      ['block6b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6c_expand_bn (BatchNormal  (None, 8, 8, 1152)  4608        ['block6c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6c_expand_activation (Act  (None, 8, 8, 1152)  0           ['block6c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6c_dwconv (DepthwiseConv2  (None, 8, 8, 1152)  28800       ['block6c_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6c_bn (BatchNormalization  (None, 8, 8, 1152)  4608        ['block6c_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6c_activation (Activation  (None, 8, 8, 1152)  0           ['block6c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6c_se_squeeze (GlobalAver  (None, 1152)        0           ['block6c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6c_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6c_se_excite (Multiply)   (None, 8, 8, 1152)   0           ['block6c_activation[0][0]',     \n",
      "                                                                  'block6c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6c_project_conv (Conv2D)  (None, 8, 8, 192)    221184      ['block6c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6c_project_bn (BatchNorma  (None, 8, 8, 192)   768         ['block6c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6c_drop (Dropout)         (None, 8, 8, 192)    0           ['block6c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_add (Add)              (None, 8, 8, 192)    0           ['block6c_drop[0][0]',           \n",
      "                                                                  'block6b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6d_expand_conv (Conv2D)   (None, 8, 8, 1152)   221184      ['block6c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6d_expand_bn (BatchNormal  (None, 8, 8, 1152)  4608        ['block6d_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6d_expand_activation (Act  (None, 8, 8, 1152)  0           ['block6d_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6d_dwconv (DepthwiseConv2  (None, 8, 8, 1152)  28800       ['block6d_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6d_bn (BatchNormalization  (None, 8, 8, 1152)  4608        ['block6d_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6d_activation (Activation  (None, 8, 8, 1152)  0           ['block6d_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6d_se_squeeze (GlobalAver  (None, 1152)        0           ['block6d_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6d_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6d_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6d_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6d_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_se_excite (Multiply)   (None, 8, 8, 1152)   0           ['block6d_activation[0][0]',     \n",
      "                                                                  'block6d_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_project_conv (Conv2D)  (None, 8, 8, 192)    221184      ['block6d_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_project_bn (BatchNorma  (None, 8, 8, 192)   768         ['block6d_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6d_drop (Dropout)         (None, 8, 8, 192)    0           ['block6d_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_add (Add)              (None, 8, 8, 192)    0           ['block6d_drop[0][0]',           \n",
      "                                                                  'block6c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block7a_expand_conv (Conv2D)   (None, 8, 8, 1152)   221184      ['block6d_add[0][0]']            \n",
      "                                                                                                  \n",
      " block7a_expand_bn (BatchNormal  (None, 8, 8, 1152)  4608        ['block7a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block7a_expand_activation (Act  (None, 8, 8, 1152)  0           ['block7a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block7a_dwconv (DepthwiseConv2  (None, 8, 8, 1152)  10368       ['block7a_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block7a_bn (BatchNormalization  (None, 8, 8, 1152)  4608        ['block7a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block7a_activation (Activation  (None, 8, 8, 1152)  0           ['block7a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block7a_se_squeeze (GlobalAver  (None, 1152)        0           ['block7a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block7a_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block7a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block7a_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block7a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block7a_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block7a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block7a_se_excite (Multiply)   (None, 8, 8, 1152)   0           ['block7a_activation[0][0]',     \n",
      "                                                                  'block7a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block7a_project_conv (Conv2D)  (None, 8, 8, 320)    368640      ['block7a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block7a_project_bn (BatchNorma  (None, 8, 8, 320)   1280        ['block7a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " top_conv (Conv2D)              (None, 8, 8, 1280)   409600      ['block7a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " top_bn (BatchNormalization)    (None, 8, 8, 1280)   5120        ['top_conv[0][0]']               \n",
      "                                                                                                  \n",
      " top_activation (Activation)    (None, 8, 8, 1280)   0           ['top_bn[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 1280)        0           ['top_activation[0][0]']         \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1024)         1311744     ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 4)            4100        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,365,415\n",
      "Trainable params: 2,666,804\n",
      "Non-trainable params: 2,698,611\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 18 Complete [01h 06m 54s]\n",
      "val_accuracy: 0.9387900233268738\n",
      "\n",
      "Best val_accuracy So Far: 0.9387900233268738\n",
      "Total elapsed time: 11d 02h 21m 11s\n",
      "\n",
      "Search: Running Trial #19\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "1280              |1280              |units\n",
      "0.4               |0.2               |dropout\n",
      "0.001             |0.001             |learning_rate\n",
      "4                 |10                |tuner/epochs\n",
      "0                 |4                 |tuner/initial_epoch\n",
      "1                 |2                 |tuner/bracket\n",
      "0                 |2                 |tuner/round\n",
      "\n",
      "Epoch 1/4\n",
      "332/332 [==============================] - 676s 2s/step - loss: 0.6367 - accuracy: 0.7400 - val_loss: 0.3679 - val_accuracy: 0.8676\n",
      "Epoch 2/4\n",
      "231/332 [===================>..........] - ETA: 3:06 - loss: 0.4629 - accuracy: 0.8235"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 72\u001b[0m\n\u001b[0;32m     69\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Perform hyperparameter tuning\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_encoded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Get the optimal hyperparameters\u001b[39;00m\n\u001b[0;32m     75\u001b[0m best_hps \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_hyperparameters(num_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:274\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    275\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:239\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m--> 239\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m    242\u001b[0m     ):\n\u001b[0;32m    243\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[0;32m    245\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[0;32m    246\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    254\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    255\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\tuners\\hyperband.py:427\u001b[0m, in \u001b[0;36mHyperband.run_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    425\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    426\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/initial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[0;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[1;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[0;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[1;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1648\u001b[0m ):\n\u001b[0;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Attempt (Without Freeze and Unfreeze) - Problem -> Infinite Loop\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import cv2\n",
    "import kerastuner as kt\n",
    "\n",
    "# Parameters\n",
    "img_size = (240, 240)\n",
    "channels = 3\n",
    "img_shape = (img_size[0], img_size[1], channels)\n",
    "num_classes = 4\n",
    "\n",
    "# Example: Convert DataFrame to numpy array\n",
    "X_train = np.array(train_df['image'].tolist())\n",
    "y_train = train_df['label'].values\n",
    "X_test = np.array(test_df['image'].tolist())\n",
    "y_test = test_df['label'].values\n",
    "\n",
    "# Ensure images have 3 channels\n",
    "X_train = np.array([cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) if img.shape[-1] != 3 else img for img in X_train])\n",
    "X_test = np.array([cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) if img.shape[-1] != 3 else img for img in X_test])\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train_encoded = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_encoded = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "# Define model builder function for Keras Tuner\n",
    "def build_model(hp):\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=img_shape)\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Tune the number of units in the dense layer\n",
    "    x = Dense(units=hp.Int('units', min_value=512, max_value=2048, step=256), activation='relu')(x)\n",
    "    \n",
    "    # Tune the dropout rate\n",
    "    x = Dropout(rate=hp.Float('dropout', min_value=0.2, max_value=0.5, step=0.1))(x)\n",
    "    \n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # Tune the learning rate for the optimizer\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Instantiate the tuner\n",
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=5,  # Set the maximum number of epochs to 5\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='efficientnet_tuning')\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "tuner.search(X_train, y_train_encoded, epochs=5, validation_data=(X_test, y_test_encoded), callbacks=[early_stopping])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Build the model with the optimal hyperparameters and train it\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, y_train_encoded, epochs=5, validation_data=(X_test, y_test_encoded), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded)\n",
    "print(f'Test accuracy: {test_accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 Complete [01h 04m 20s]\n",
      "val_accuracy: 0.927402138710022\n",
      "\n",
      "Best val_accuracy So Far: 0.9473309516906738\n",
      "Total elapsed time: 13d 04h 39m 00s\n",
      "\n",
      "Search: Running Trial #27\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "1536              |1024              |units\n",
      "0.3               |0.2               |dropout\n",
      "0.01              |0.001             |learning_rate\n",
      "10                |10                |tuner/epochs\n",
      "0                 |4                 |tuner/initial_epoch\n",
      "0                 |1                 |tuner/bracket\n",
      "0                 |1                 |tuner/round\n",
      "\n",
      "Epoch 1/10\n",
      "332/332 [==============================] - 662s 2s/step - loss: 0.8550 - accuracy: 0.7264 - val_loss: 0.4000 - val_accuracy: 0.8441\n",
      "Epoch 2/10\n",
      "332/332 [==============================] - 754s 2s/step - loss: 0.5997 - accuracy: 0.7609 - val_loss: 0.3904 - val_accuracy: 0.8569\n",
      "Epoch 3/10\n",
      "270/332 [=======================>......] - ETA: 1:46 - loss: 0.5531 - accuracy: 0.7874"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 72\u001b[0m\n\u001b[0;32m     69\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Perform hyperparameter tuning\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_encoded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Get the optimal hyperparameters\u001b[39;00m\n\u001b[0;32m     75\u001b[0m best_hps \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_hyperparameters(num_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:274\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    275\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:239\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m--> 239\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m    242\u001b[0m     ):\n\u001b[0;32m    243\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[0;32m    245\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[0;32m    246\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    254\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    255\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\tuners\\hyperband.py:427\u001b[0m, in \u001b[0;36mHyperband.run_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    425\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    426\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/initial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[0;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[1;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[0;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[1;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1648\u001b[0m ):\n\u001b[0;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Attempt (Only Freeze) - Problem -> Infinite Loop\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import cv2\n",
    "import keras_tuner as kt\n",
    "\n",
    "# Parameters\n",
    "img_size = (240, 240)\n",
    "channels = 3\n",
    "img_shape = (img_size[0], img_size[1], channels)\n",
    "num_classes = 4\n",
    "\n",
    "# Example: Convert DataFrame to numpy array\n",
    "X_train = np.array(train_df['image'].tolist())\n",
    "y_train = train_df['label'].values\n",
    "X_test = np.array(test_df['image'].tolist())\n",
    "y_test = test_df['label'].values\n",
    "\n",
    "# Ensure images have 3 channels\n",
    "X_train = np.array([cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) if img.shape[-1] != 3 else img for img in X_train])\n",
    "X_test = np.array([cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) if img.shape[-1] != 3 else img for img in X_test])\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train_encoded = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_encoded = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "# Define model builder function for Keras Tuner\n",
    "def build_model(hp):\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=img_shape)\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Tune the number of units in the dense layer\n",
    "    x = Dense(units=hp.Int('units', min_value=512, max_value=2048, step=256), activation='relu')(x)\n",
    "    \n",
    "    # Tune the dropout rate\n",
    "    x = Dropout(rate=hp.Float('dropout', min_value=0.2, max_value=0.5, step=0.1))(x)\n",
    "    \n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # Tune the learning rate for the optimizer\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Instantiate the tuner\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=5,  # Set the maximum number of epochs per trial\n",
    "    factor=3,\n",
    "    directory='my_dir',\n",
    "    project_name='efficientnet_tuning'\n",
    ")\n",
    "\n",
    "# Add EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "tuner.search(X_train, y_train_encoded, epochs=5, validation_data=(X_test, y_test_encoded), callbacks=[early_stopping])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Build the model with the optimal hyperparameters and train it\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Freeze the base model layers again for initial training\n",
    "for layer in model.layers[:-3]:  # Assuming the last 3 layers are the custom layers\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model with the best hyperparameters\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_hps.get('learning_rate')),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(X_train, y_train_encoded, epochs=5, validation_data=(X_test, y_test_encoded), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded)\n",
    "print(f'Test accuracy: {test_accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 Complete [00h 23m 02s]\n",
      "val_accuracy: 0.8604982495307922\n",
      "\n",
      "Best val_accuracy So Far: 0.8939501643180847\n",
      "Total elapsed time: 9d 22h 19m 05s\n",
      "\n",
      "Search: Running Trial #9\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "768               |1280              |units\n",
      "0.2               |0.3               |dropout\n",
      "0.0001            |0.001             |learning_rate\n",
      "2                 |2                 |tuner/epochs\n",
      "0                 |0                 |tuner/initial_epoch\n",
      "2                 |2                 |tuner/bracket\n",
      "0                 |0                 |tuner/round\n",
      "\n",
      "Epoch 1/2\n",
      "117/332 [=========>....................] - ETA: 6:46 - loss: 0.8602 - accuracy: 0.6464"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 71\u001b[0m\n\u001b[0;32m     68\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Perform hyperparameter tuning\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_encoded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Get the optimal hyperparameters\u001b[39;00m\n\u001b[0;32m     74\u001b[0m best_hps \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_hyperparameters(num_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:274\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    275\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:239\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m--> 239\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m    242\u001b[0m     ):\n\u001b[0;32m    243\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[0;32m    245\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[0;32m    246\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    254\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    255\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\tuners\\hyperband.py:427\u001b[0m, in \u001b[0;36mHyperband.run_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    425\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    426\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/initial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[0;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[1;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[0;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[1;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1648\u001b[0m ):\n\u001b[0;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Attempt (Only Unfreeze) - Problem -> Infinite Loop\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import cv2\n",
    "import kerastuner as kt\n",
    "\n",
    "# Parameters\n",
    "img_size = (240, 240)\n",
    "channels = 3\n",
    "img_shape = (img_size[0], img_size[1], channels)\n",
    "num_classes = 4\n",
    "\n",
    "# Example: Convert DataFrame to numpy array\n",
    "X_train = np.array(train_df['image'].tolist())\n",
    "y_train = train_df['label'].values\n",
    "X_test = np.array(test_df['image'].tolist())\n",
    "y_test = test_df['label'].values\n",
    "\n",
    "# Ensure images have 3 channels\n",
    "X_train = np.array([cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) if img.shape[-1] != 3 else img for img in X_train])\n",
    "X_test = np.array([cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) if img.shape[-1] != 3 else img for img in X_test])\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train_encoded = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_encoded = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "# Define model builder function for Keras Tuner\n",
    "def build_model(hp):\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=img_shape)\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Tune the number of units in the dense layer\n",
    "    x = Dense(units=hp.Int('units', min_value=512, max_value=2048, step=256), activation='relu')(x)\n",
    "    \n",
    "    # Tune the dropout rate\n",
    "    x = Dropout(rate=hp.Float('dropout', min_value=0.2, max_value=0.5, step=0.1))(x)\n",
    "    \n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # Tune the learning rate for the optimizer\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Instantiate the tuner\n",
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='efficientnet_tuning')\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "tuner.search(X_train, y_train_encoded, epochs=10, validation_data=(X_test, y_test_encoded), callbacks=[early_stopping])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Build the model with the optimal hyperparameters and train it\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, y_train_encoded, epochs=10, validation_data=(X_test, y_test_encoded), callbacks=[early_stopping])\n",
    "\n",
    "# Unfreeze some layers and fine-tune\n",
    "for layer in base_model.layers[-20:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile the model with a lower learning rate\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Continue training\n",
    "history_fine = model.fit(X_train, y_train_encoded, epochs=5, validation_data=(X_test, y_test_encoded))\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded)\n",
    "print(f'Test accuracy: {test_accuracy * 100:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-15.m121",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-15:m121"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
